{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Deprived Area Mapping using Open Source Geospatial Data\n",
    "\n",
    "Prepared by Maxwell Owusu\n",
    "George Washington University\n",
    "Fall, 2022"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import os\n",
    "\n",
    "import utils\n",
    "import util_preprocess"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\r\n",
      "Solving environment: done\r\n",
      "\r\n",
      "\r\n",
      "==> WARNING: A newer version of conda exists. <==\r\n",
      "  current version: 4.12.0\r\n",
      "  latest version: 22.11.1\r\n",
      "\r\n",
      "Please update conda by running\r\n",
      "\r\n",
      "    $ conda update -n base -c defaults conda\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "## Package Plan ##\r\n",
      "\r\n",
      "  environment location: /home/owusu/miniconda3/envs/IDEAMAPS\r\n",
      "\r\n",
      "  added / updated specs:\r\n",
      "    - seaborn\r\n",
      "\r\n",
      "\r\n",
      "The following packages will be downloaded:\r\n",
      "\r\n",
      "    package                    |            build\r\n",
      "    ---------------------------|-----------------\r\n",
      "    blas-1.0                   |              mkl           6 KB\r\n",
      "    bottleneck-1.3.5           |  py310ha9d4c09_0         274 KB\r\n",
      "    ca-certificates-2022.12.7  |       ha878542_0         143 KB  conda-forge\r\n",
      "    certifi-2022.12.7          |     pyhd8ed1ab_0         147 KB  conda-forge\r\n",
      "    fftw-3.3.10                |nompi_h77c792f_102         6.4 MB  conda-forge\r\n",
      "    intel-openmp-2021.4.0      |    h06a4308_3561         4.2 MB\r\n",
      "    kiwisolver-1.4.2           |  py310h295c915_0         752 KB\r\n",
      "    libtiff-4.4.0              |       hecacb30_2         526 KB\r\n",
      "    matplotlib-base-3.4.3      |  py310h23f4a51_2         7.3 MB  conda-forge\r\n",
      "    mkl-2021.4.0               |     h06a4308_640       142.6 MB\r\n",
      "    mkl-service-2.4.0          |  py310ha2c4b55_0         285 KB  conda-forge\r\n",
      "    mkl_fft-1.3.1              |  py310h2b4bcf5_1         946 KB  conda-forge\r\n",
      "    mkl_random-1.2.2           |  py310h00e6091_0        1009 KB\r\n",
      "    numexpr-2.8.4              |  py310h8879344_0         134 KB\r\n",
      "    numpy-1.23.4               |  py310hd5efca6_0          10 KB\r\n",
      "    numpy-base-1.23.4          |  py310h8e6c178_0         6.7 MB\r\n",
      "    packaging-22.0             |     pyhd8ed1ab_0          40 KB  conda-forge\r\n",
      "    pandas-1.5.2               |  py310h1128e8f_0        11.9 MB\r\n",
      "    patsy-0.5.3                |     pyhd8ed1ab_0         189 KB  conda-forge\r\n",
      "    pillow-9.2.0               |  py310hace64e9_1         1.2 MB\r\n",
      "    pyparsing-3.0.9            |     pyhd8ed1ab_0          79 KB  conda-forge\r\n",
      "    python-dateutil-2.8.2      |     pyhd8ed1ab_0         240 KB  conda-forge\r\n",
      "    python_abi-3.10            |          2_cp310           4 KB  conda-forge\r\n",
      "    pytz-2022.6                |     pyhd8ed1ab_0         235 KB  conda-forge\r\n",
      "    scipy-1.9.3                |  py310hd5efca6_0        23.1 MB\r\n",
      "    seaborn-0.12.1             |       hd8ed1ab_0           5 KB  conda-forge\r\n",
      "    seaborn-base-0.12.1        |     pyhd8ed1ab_0         217 KB  conda-forge\r\n",
      "    six-1.16.0                 |     pyh6c4a22f_0          14 KB  conda-forge\r\n",
      "    statsmodels-0.13.2         |  py310h7f8727e_0        14.6 MB\r\n",
      "    tornado-6.1                |  py310h5764c6d_3         657 KB  conda-forge\r\n",
      "    typing_extensions-4.4.0    |     pyha770c72_0          29 KB  conda-forge\r\n",
      "    ------------------------------------------------------------\r\n",
      "                                           Total:       223.8 MB\r\n",
      "\r\n",
      "The following NEW packages will be INSTALLED:\r\n",
      "\r\n",
      "  blas               pkgs/main/linux-64::blas-1.0-mkl\r\n",
      "  bottleneck         pkgs/main/linux-64::bottleneck-1.3.5-py310ha9d4c09_0\r\n",
      "  cycler             conda-forge/noarch::cycler-0.11.0-pyhd8ed1ab_0\r\n",
      "  fftw               conda-forge/linux-64::fftw-3.3.10-nompi_h77c792f_102\r\n",
      "  freetype           conda-forge/linux-64::freetype-2.10.4-h0708190_1\r\n",
      "  giflib             conda-forge/linux-64::giflib-5.2.1-h36c2ea0_2\r\n",
      "  intel-openmp       pkgs/main/linux-64::intel-openmp-2021.4.0-h06a4308_3561\r\n",
      "  jpeg               conda-forge/linux-64::jpeg-9e-h166bdaf_1\r\n",
      "  kiwisolver         pkgs/main/linux-64::kiwisolver-1.4.2-py310h295c915_0\r\n",
      "  lcms2              conda-forge/linux-64::lcms2-2.12-hddcbb42_0\r\n",
      "  lerc               conda-forge/linux-64::lerc-3.0-h9c3ff4c_0\r\n",
      "  libdeflate         pkgs/main/linux-64::libdeflate-1.8-h7f8727e_5\r\n",
      "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-12.2.0-h69a702a_19\r\n",
      "  libgfortran5       conda-forge/linux-64::libgfortran5-12.2.0-h337968e_19\r\n",
      "  libpng             pkgs/main/linux-64::libpng-1.6.37-hbc83047_0\r\n",
      "  libtiff            pkgs/main/linux-64::libtiff-4.4.0-hecacb30_2\r\n",
      "  libwebp            pkgs/main/linux-64::libwebp-1.2.4-h11a3e52_0\r\n",
      "  libwebp-base       pkgs/main/linux-64::libwebp-base-1.2.4-h5eee18b_0\r\n",
      "  lz4-c              conda-forge/linux-64::lz4-c-1.9.3-h9c3ff4c_1\r\n",
      "  matplotlib-base    conda-forge/linux-64::matplotlib-base-3.4.3-py310h23f4a51_2\r\n",
      "  mkl                pkgs/main/linux-64::mkl-2021.4.0-h06a4308_640\r\n",
      "  mkl-service        conda-forge/linux-64::mkl-service-2.4.0-py310ha2c4b55_0\r\n",
      "  mkl_fft            conda-forge/linux-64::mkl_fft-1.3.1-py310h2b4bcf5_1\r\n",
      "  mkl_random         pkgs/main/linux-64::mkl_random-1.2.2-py310h00e6091_0\r\n",
      "  numexpr            pkgs/main/linux-64::numexpr-2.8.4-py310h8879344_0\r\n",
      "  numpy              pkgs/main/linux-64::numpy-1.23.4-py310hd5efca6_0\r\n",
      "  numpy-base         pkgs/main/linux-64::numpy-base-1.23.4-py310h8e6c178_0\r\n",
      "  packaging          conda-forge/noarch::packaging-22.0-pyhd8ed1ab_0\r\n",
      "  pandas             pkgs/main/linux-64::pandas-1.5.2-py310h1128e8f_0\r\n",
      "  patsy              conda-forge/noarch::patsy-0.5.3-pyhd8ed1ab_0\r\n",
      "  pillow             pkgs/main/linux-64::pillow-9.2.0-py310hace64e9_1\r\n",
      "  pyparsing          conda-forge/noarch::pyparsing-3.0.9-pyhd8ed1ab_0\r\n",
      "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.2-pyhd8ed1ab_0\r\n",
      "  python_abi         conda-forge/linux-64::python_abi-3.10-2_cp310\r\n",
      "  pytz               conda-forge/noarch::pytz-2022.6-pyhd8ed1ab_0\r\n",
      "  scipy              pkgs/main/linux-64::scipy-1.9.3-py310hd5efca6_0\r\n",
      "  seaborn            conda-forge/noarch::seaborn-0.12.1-hd8ed1ab_0\r\n",
      "  seaborn-base       conda-forge/noarch::seaborn-base-0.12.1-pyhd8ed1ab_0\r\n",
      "  six                conda-forge/noarch::six-1.16.0-pyh6c4a22f_0\r\n",
      "  statsmodels        pkgs/main/linux-64::statsmodels-0.13.2-py310h7f8727e_0\r\n",
      "  tornado            conda-forge/linux-64::tornado-6.1-py310h5764c6d_3\r\n",
      "  typing_extensions  conda-forge/noarch::typing_extensions-4.4.0-pyha770c72_0\r\n",
      "  zstd               pkgs/main/linux-64::zstd-1.5.2-ha4553b6_0\r\n",
      "\r\n",
      "The following packages will be UPDATED:\r\n",
      "\r\n",
      "  ca-certificates    pkgs/main::ca-certificates-2022.10.11~ --> conda-forge::ca-certificates-2022.12.7-ha878542_0\r\n",
      "  certifi            pkgs/main/linux-64::certifi-2022.9.24~ --> conda-forge/noarch::certifi-2022.12.7-pyhd8ed1ab_0\r\n",
      "\r\n",
      "\r\n",
      "Proceed ([y]/n)? ^C\r\n",
      "\r\n",
      "CondaSystemExit: \r\n",
      "Operation aborted.  Exiting.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# import seaborn as sns\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set working directory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "# Get abosolute path of the current folder\n",
    "FPATH = '/media/owusu/Extreme SSD/IDEAMAPS/Training_Dataset/Accra'\n",
    "\n",
    "# Get abosolute output path of te current folder\n",
    "OUTPUT = '/media/owusu/Extreme SSD/IDEAMAPS/Training_Dataset/Accra/'\n",
    "\n",
    "target = 'class'\n",
    "\n",
    "# Random seed\n",
    "random_seed = 42\n",
    "# Set random seed in numpy\n",
    "np.random.seed(random_seed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing\n",
    "### Load covariate features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bands 53\n",
      "height 562\n",
      "width 842\n"
     ]
    }
   ],
   "source": [
    "PATH= f'/media/owusu/Extreme SSD/IDEAMAPS/covariate_feature_53bands/acc_covariate_compilation_53bands.tif'\n",
    "img = utils.read_image(PATH)\n",
    "img_arr=img[0]\n",
    "img_gt=img[1]\n",
    "img_georef=img[2]\n",
    "\n",
    "# Process spfea features, get the width, height and number of bands\n",
    "n = img_arr.shape[0]\n",
    "print ('number of bands',n) # number of bands\n",
    "h = img_arr.shape[1]\n",
    "print ('height', h) # height\n",
    "w = img_arr.shape[2]\n",
    "print ('width', w) # width"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convert covariate array to pandas dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 562, 842)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   fs_dist_fs_2020  fs_dist_school_2020  in_dist_rd_2016  \\\n0          -9999.0              -9999.0          -9999.0   \n1          -9999.0              -9999.0          -9999.0   \n2          -9999.0              -9999.0          -9999.0   \n3          -9999.0              -9999.0          -9999.0   \n4          -9999.0              -9999.0          -9999.0   \n\n   in_dist_rd_intersect_2016  in_dist_waterway_2016  in_night_light_2016  \\\n0                    -9999.0                -9999.0              -9999.0   \n1                    -9999.0                -9999.0              -9999.0   \n2                    -9999.0                -9999.0              -9999.0   \n3                    -9999.0                -9999.0              -9999.0   \n4                    -9999.0                -9999.0              -9999.0   \n\n   ph_base_water_2010  ph_bio_dvst_2015  ph_climate_risk_2020  \\\n0             -9999.0           -9999.0               -9999.0   \n1             -9999.0           -9999.0               -9999.0   \n2             -9999.0           -9999.0               -9999.0   \n3             -9999.0           -9999.0               -9999.0   \n4             -9999.0           -9999.0               -9999.0   \n\n   ph_dist_aq_veg_2015  ...  sh_ethno_den_2020  uu_bld_count_2020  \\\n0              -9999.0  ...            -9999.0            -9999.0   \n1              -9999.0  ...            -9999.0            -9999.0   \n2              -9999.0  ...            -9999.0            -9999.0   \n3              -9999.0  ...            -9999.0            -9999.0   \n4              -9999.0  ...            -9999.0            -9999.0   \n\n   uu_bld_den_2020  ho_impr_housing_2015  fs_dist_hf_2019  po_hrsl_2018  \\\n0          -9999.0               -9999.0    -3.402823e+38       -9999.0   \n1          -9999.0               -9999.0    -3.402823e+38       -9999.0   \n2          -9999.0               -9999.0    -3.402823e+38       -9999.0   \n3          -9999.0               -9999.0    -3.402823e+38       -9999.0   \n4          -9999.0               -9999.0    -3.402823e+38       -9999.0   \n\n   po_wp_2020  ph_dist_riv_network_2007  uu_urb_bldg_2018  \\\n0     -9999.0                     255.0           -9999.0   \n1     -9999.0                     255.0           -9999.0   \n2     -9999.0                     255.0           -9999.0   \n3     -9999.0                     255.0           -9999.0   \n4     -9999.0                     255.0           -9999.0   \n\n   ses_dist_gov_office_2022  \n0                  0.344877  \n1                  0.344203  \n2                  0.343529  \n3                  0.342857  \n4                  0.342185  \n\n[5 rows x 53 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fs_dist_fs_2020</th>\n      <th>fs_dist_school_2020</th>\n      <th>in_dist_rd_2016</th>\n      <th>in_dist_rd_intersect_2016</th>\n      <th>in_dist_waterway_2016</th>\n      <th>in_night_light_2016</th>\n      <th>ph_base_water_2010</th>\n      <th>ph_bio_dvst_2015</th>\n      <th>ph_climate_risk_2020</th>\n      <th>ph_dist_aq_veg_2015</th>\n      <th>...</th>\n      <th>sh_ethno_den_2020</th>\n      <th>uu_bld_count_2020</th>\n      <th>uu_bld_den_2020</th>\n      <th>ho_impr_housing_2015</th>\n      <th>fs_dist_hf_2019</th>\n      <th>po_hrsl_2018</th>\n      <th>po_wp_2020</th>\n      <th>ph_dist_riv_network_2007</th>\n      <th>uu_urb_bldg_2018</th>\n      <th>ses_dist_gov_office_2022</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>...</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-3.402823e+38</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>255.0</td>\n      <td>-9999.0</td>\n      <td>0.344877</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>...</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-3.402823e+38</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>255.0</td>\n      <td>-9999.0</td>\n      <td>0.344203</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>...</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-3.402823e+38</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>255.0</td>\n      <td>-9999.0</td>\n      <td>0.343529</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>...</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-3.402823e+38</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>255.0</td>\n      <td>-9999.0</td>\n      <td>0.342857</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>...</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-3.402823e+38</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>255.0</td>\n      <td>-9999.0</td>\n      <td>0.342185</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 53 columns</p>\n</div>"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandname = ['fs_dist_fs_2020', 'fs_dist_school_2020', 'in_dist_rd_2016', 'in_dist_rd_intersect_2016', 'in_dist_waterway_2016', 'in_night_light_2016',\n",
    "'ph_base_water_2010', 'ph_bio_dvst_2015', 'ph_climate_risk_2020', 'ph_dist_aq_veg_2015', 'ph_dist_art_surface_2015', 'ph_dist_bare_2015',\n",
    "'ph_dist_cultivated_2015', 'ph_dist_herb_2015', 'ph_dist_inland_water_2018', 'ph_dist_open_coast_2020', 'ph_dist_shrub_2015', 'ph_dist_sparse_veg_2015',\n",
    "'ph_dist_woody_tree_2015', 'ph_gdmhz_2005', 'ph_grd_water_2000', 'ph_hzd_index_2011', 'ph_land_c1_2019', 'ph_land_c2_2020', 'ph_max_tem_2019',\n",
    "'ph_ndvi_2019', 'ph_pm25_2016', 'ph_slope_2000', 'ses_an_visits_2016', 'ses_child_stunted_2016', 'ses_dpt3_2016', 'ses_hf_delivery_2016',\n",
    "'ses_impr_water_src_2016', 'ses_ITN_2016', 'ses_m_lit_2016', 'ses_measles_2016', 'ses_odef_2016', 'ses_pfpr_2016', 'ses_preg_2016',\n",
    "'ses_unmet_need_2016', 'ses_w_lit_2016', 'sh_dist_mnr_pofw_2019', 'sh_dist_pofw_2019', 'sh_ethno_den_2020', 'uu_bld_count_2020',\n",
    "'uu_bld_den_2020', 'ho_impr_housing_2015', 'fs_dist_hf_2019', 'po_hrsl_2018', 'po_wp_2020', 'ph_dist_riv_network_2007', 'uu_urb_bldg_2018', 'ses_dist_gov_office_2022']\n",
    "\n",
    "\n",
    "# Make dataframe\n",
    "df_data=utils.make_data_frame(img_arr, bandname)\n",
    "df_data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load training data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(562, 842)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[     0,   5085],\n       [     1,   1739],\n       [     3, 466380]])"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PATH = f'{FPATH}/Tiles_merge.tif'\n",
    "PATH = '/media/owusu/Extreme SSD/IDEAMAPS/Training_Dataset/Accra/New Folder/acc_150m_1000m_raster.tif'\n",
    "train_set = utils.read_image(PATH)\n",
    "train_array=train_set[0]\n",
    "train_array = train_array.astype(int)\n",
    "train_gt=train_set[1]\n",
    "train_georef=train_set[2]\n",
    "print (train_array.shape)\n",
    "\n",
    "# Check unique values\n",
    "(unique, counts) = np.unique(train_array, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convert array to pandas dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([3, 1, 0])]"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_col_name = [\"class\"]\n",
    "tr_img_data = train_array.flatten()\n",
    "df_train = pd.DataFrame(tr_img_data, columns=train_col_name)\n",
    "df_train.head()\n",
    "[df_train['class'].unique()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "### Concatenate training and covariate features\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(473204, 54)\n"
     ]
    }
   ],
   "source": [
    "# concat trainset and data\n",
    "data_concat = pd.concat([df_train, df_data], axis=1)\n",
    "print (data_concat.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([3, 1, 0])]"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[data_concat['class'].unique()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6824, 54)\n"
     ]
    },
    {
     "data": {
      "text/plain": "[array([1, 0])]"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = data_concat.loc[data_concat['class'] != 3]\n",
    "print(df_full.shape)\n",
    "df_full.head()\n",
    "[df_full['class'].unique()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "### Drop unwanted columns\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "# df_full = df_full.drop(columns=['ph_gdmhz_2005', 'ph_grd_water_2000', 'ph_hzd_index_2011', 'ph_base_water_2010', 'ses_pfpr_2016', 'ph_land_c1_2019', 'ph_land_c2_2020'])\n",
    "df_full = df_full[['class', 'po_wp_2020', 'po_hrsl_2018', 'uu_bld_den_2020', 'uu_bld_count_2020', 'ph_slope_2000', 'ph_pm25_2016', 'ph_ndvi_2019', 'ph_bio_dvst_2015', 'ph_max_tem_2019', 'in_night_light_2016']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split into train, validation and test\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train (6687, 11)\n",
      "df_val (68, 11)\n",
      "df_test (69, 11)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divide the training data into training (80%) and testing (20%)\n",
    "df_train, df_test = train_test_split(df_full, train_size=0.99, random_state=random_seed)\n",
    "# Reset the index\n",
    "df_train, df_test = df_train.reset_index(drop=True), df_test.reset_index(drop=True)\n",
    "\n",
    "# Divide the training data into training (80%) and validation (20%)\n",
    "df_train, df_val = train_test_split(df_train, train_size=0.99, random_state=random_seed)\n",
    "# Reset the index\n",
    "df_train, df_val = df_train.reset_index(drop=True), df_val.reset_index(drop=True)\n",
    "\n",
    "print('df_train', df_train.shape)\n",
    "print('df_val', df_val.shape)\n",
    "print('df_test', df_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Handling missing data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "                 var  proportion    dtype\n0       po_hrsl_2018    0.150791  float64\n1      ph_slope_2000    0.101407  float64\n2         po_wp_2020    0.061401  float64\n3    uu_bld_den_2020    0.061254  float64\n4  uu_bld_count_2020    0.061254  float64",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>var</th>\n      <th>proportion</th>\n      <th>dtype</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>po_hrsl_2018</td>\n      <td>0.150791</td>\n      <td>float64</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ph_slope_2000</td>\n      <td>0.101407</td>\n      <td>float64</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>po_wp_2020</td>\n      <td>0.061401</td>\n      <td>float64</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>uu_bld_den_2020</td>\n      <td>0.061254</td>\n      <td>float64</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>uu_bld_count_2020</td>\n      <td>0.061254</td>\n      <td>float64</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handling missing data\n",
    "# Combine df_train, df_val and df_test\n",
    "df = pd.concat([df_train, df_val, df_test], sort=False)\n",
    "\n",
    "# Call nan_checker on df\n",
    "df_nan = util_preprocess.nan_checker(df)\n",
    "\n",
    "# Print df_nan\n",
    "df_nan\n",
    "\n",
    "# Print the unique data type of variables with NaN\n",
    "pd.DataFrame(df_nan['dtype'].unique(), columns=['dtype'])\n",
    "\n",
    "# Get the variables with missing values, their proportion of missing values and data type\n",
    "df_miss = df_nan[df_nan['dtype'] == 'float64'].reset_index(drop=True)\n",
    "\n",
    "# Print df_miss\n",
    "df_miss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "# Imputing missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# If there are missing values\n",
    "if len(df_miss['var']) > 0:\n",
    "    # The SimpleImputer\n",
    "    si = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "    # Impute the variables with missing values in df_train, df_val and df_test\n",
    "    df_train[df_miss['var']] = si.fit_transform(df_train[df_miss['var']])\n",
    "    df_val[df_miss['var']] = si.transform(df_val[df_miss['var']])\n",
    "    df_test[df_miss['var']] = si.transform(df_test[df_miss['var']])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encoding data\n",
    " Checking for categorical features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [var, nunique]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>var</th>\n      <th>nunique</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine df_train, df_val and df_test\n",
    "df = pd.concat([df_train, df_val, df_test], sort=False)\n",
    "\n",
    "# Print the unique data type of variables in df\n",
    "pd.DataFrame(df.dtypes.unique(), columns=['dtype'])\n",
    "\n",
    "# Call cat_var_checker on df\n",
    "# See the implementation in pmlm_utilities.ipynb\n",
    "df_cat = util_preprocess.cat_var_checker(df)\n",
    "\n",
    "# Print the dataframe\n",
    "df_cat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Separating the training, validation and test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "\n",
    "# Separating the training data\n",
    "df_train = df.iloc[:df_train.shape[0], :]\n",
    "\n",
    "# Separating the validation data\n",
    "df_val = df.iloc[df_train.shape[0]:df_train.shape[0] + df_val.shape[0], :]\n",
    "\n",
    "# Separating the test data\n",
    "df_test = df.iloc[df_train.shape[0] + df_val.shape[0]:, :]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "# Get the feature matrix\n",
    "X_train = df_train[np.setdiff1d(df_train.columns, [target])].values\n",
    "X_val = df_val[np.setdiff1d(df_val.columns, [target])].values\n",
    "X_test = df_test[np.setdiff1d(df_test.columns, [target])].values\n",
    "\n",
    "# Get the target vector\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values\n",
    "y_test = df_test[target].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# # The SimpleImputer\n",
    "# si = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "# X_train = si.fit_transform(X_train)\n",
    "# X_val = si.fit_transform(X_val)\n",
    "# X_test = si.fit_transform(X_test)\n",
    "\n",
    "# # The StandardScaler\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# ss = StandardScaler()\n",
    "#\n",
    "# # Standardize the training data\n",
    "# X_train = ss.fit_transform(X_train)\n",
    "#\n",
    "# # Standardize the validation data\n",
    "# X_val = ss.transform(X_val)\n",
    "#\n",
    "# # Standardize the test data\n",
    "# X_test = ss.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing Test Data\n",
    "Transfer learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "740\n",
      "655\n",
      "(53, 740, 655)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   fs_dist_fs_2020  fs_dist_school_2020  in_dist_rd_2016  \\\n0          -9999.0              -9999.0          -9999.0   \n1          -9999.0              -9999.0          -9999.0   \n2          -9999.0              -9999.0          -9999.0   \n3          -9999.0              -9999.0          -9999.0   \n4          -9999.0              -9999.0          -9999.0   \n\n   in_dist_rd_intersect_2016  in_dist_waterway_2016  in_night_light_2016  \\\n0                    -9999.0                -9999.0              -9999.0   \n1                    -9999.0                -9999.0              -9999.0   \n2                    -9999.0                -9999.0              -9999.0   \n3                    -9999.0                -9999.0              -9999.0   \n4                    -9999.0                -9999.0              -9999.0   \n\n   ph_base_water_2010  ph_bio_dvst_2015  ph_climate_risk_2020  \\\n0             -9999.0           -9999.0               -9999.0   \n1             -9999.0           -9999.0               -9999.0   \n2             -9999.0           -9999.0               -9999.0   \n3             -9999.0           -9999.0               -9999.0   \n4             -9999.0           -9999.0               -9999.0   \n\n   ph_dist_aq_veg_2015  ...  sh_ethno_den_2020  uu_bld_count_2020  \\\n0              -9999.0  ...            -9999.0            -9999.0   \n1              -9999.0  ...            -9999.0            -9999.0   \n2              -9999.0  ...            -9999.0            -9999.0   \n3              -9999.0  ...            -9999.0            -9999.0   \n4              -9999.0  ...            -9999.0            -9999.0   \n\n   uu_bld_den_2020  ho_impr_housing_2015  fs_dist_hf_2019  po_hrsl_2018  \\\n0          -9999.0               -9999.0          -9999.0       -9999.0   \n1          -9999.0               -9999.0          -9999.0       -9999.0   \n2          -9999.0               -9999.0          -9999.0       -9999.0   \n3          -9999.0               -9999.0          -9999.0       -9999.0   \n4          -9999.0               -9999.0          -9999.0       -9999.0   \n\n   po_wp_2020  ph_dist_riv_network_2007  uu_urb_bldg_2018  \\\n0     -9999.0                   -9999.0               3.0   \n1     -9999.0                   -9999.0               3.0   \n2     -9999.0                   -9999.0               3.0   \n3     -9999.0                   -9999.0               3.0   \n4     -9999.0                   -9999.0               3.0   \n\n   ses_dist_gov_office_2022  \n0                   -9999.0  \n1                   -9999.0  \n2                   -9999.0  \n3                   -9999.0  \n4                   -9999.0  \n\n[5 rows x 53 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fs_dist_fs_2020</th>\n      <th>fs_dist_school_2020</th>\n      <th>in_dist_rd_2016</th>\n      <th>in_dist_rd_intersect_2016</th>\n      <th>in_dist_waterway_2016</th>\n      <th>in_night_light_2016</th>\n      <th>ph_base_water_2010</th>\n      <th>ph_bio_dvst_2015</th>\n      <th>ph_climate_risk_2020</th>\n      <th>ph_dist_aq_veg_2015</th>\n      <th>...</th>\n      <th>sh_ethno_den_2020</th>\n      <th>uu_bld_count_2020</th>\n      <th>uu_bld_den_2020</th>\n      <th>ho_impr_housing_2015</th>\n      <th>fs_dist_hf_2019</th>\n      <th>po_hrsl_2018</th>\n      <th>po_wp_2020</th>\n      <th>ph_dist_riv_network_2007</th>\n      <th>uu_urb_bldg_2018</th>\n      <th>ses_dist_gov_office_2022</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>...</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>3.0</td>\n      <td>-9999.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>...</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>3.0</td>\n      <td>-9999.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>...</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>3.0</td>\n      <td>-9999.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>...</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>3.0</td>\n      <td>-9999.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>...</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>-9999.0</td>\n      <td>3.0</td>\n      <td>-9999.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 53 columns</p>\n</div>"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make dataframe\n",
    "\n",
    "PATH= f'/media/owusu/Extreme SSD/IDEAMAPS/covariate_feature_53bands/nai_covariate_compilation_53bands.tif'\n",
    "img = utils.read_image(PATH)\n",
    "img_arr=img[0]\n",
    "img_gt=img[1]\n",
    "img_georef=img[2]\n",
    "\n",
    "# Process spfea features, get the width, height and number of bands\n",
    "n = img_arr.shape[0]\n",
    "print (n) # number of bands\n",
    "h = img_arr.shape[1]\n",
    "print (h) # height\n",
    "w = img_arr.shape[2]\n",
    "print (w) # width\n",
    "\n",
    "df_data=utils.make_data_frame(img_arr, bandname)\n",
    "df_data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(740, 655)\n",
      "[[     0   2657]\n",
      " [     1   1311]\n",
      " [     3 480732]]\n",
      "(484700, 54)\n"
     ]
    }
   ],
   "source": [
    "# PATH = f'{FPATH}/Tiles_merge.tif'\n",
    "PATH = '/media/owusu/Extreme SSD/IDEAMAPS/Training_Dataset/Nairobi/Nairobi_updated_tiles/nairobi_slums_SDI/Nairobi_tiles_raster.tif'\n",
    "train_set = utils.read_image(PATH)\n",
    "train_array=train_set[0]\n",
    "train_array = train_array.astype(int)\n",
    "train_gt=train_set[1]\n",
    "train_georef=train_set[2]\n",
    "print (train_array.shape)\n",
    "\n",
    "# Check unique values\n",
    "(unique, counts) = np.unique(train_array, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)\n",
    "\n",
    "train_col_name = [\"class\"]\n",
    "tr_img_data = train_array.flatten()\n",
    "df_train = pd.DataFrame(tr_img_data, columns=train_col_name)\n",
    "df_train.head()\n",
    "[df_train['class'].unique()]\n",
    "\n",
    "# concat trainset and data\n",
    "data_concat = pd.concat([df_train, df_data], axis=1)\n",
    "print (data_concat.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3968, 54)\n"
     ]
    },
    {
     "data": {
      "text/plain": "[array([0, 1])]"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = data_concat.loc[data_concat['class'] != 3]\n",
    "print(df_full.shape)\n",
    "df_full.head()\n",
    "[df_full['class'].unique()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "# X = df_full.drop(columns=['class','ph_gdmhz_2005', 'ph_grd_water_2000', 'ph_hzd_index_2011', 'ph_base_water_2010', 'ses_pfpr_2016', 'ph_land_c1_2019', 'ph_land_c2_2020'])\n",
    "X = df_full[['po_wp_2020', 'po_hrsl_2018', 'uu_bld_den_2020', 'uu_bld_count_2020', 'ph_slope_2000', 'ph_pm25_2016', 'ph_ndvi_2019', 'ph_bio_dvst_2015', 'ph_max_tem_2019', 'in_night_light_2016']]\n",
    "y = df_full['class'].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['po_wp_2020', 'po_hrsl_2018', 'uu_bld_den_2020', 'uu_bld_count_2020',\n       'ph_slope_2000', 'ph_pm25_2016', 'ph_ndvi_2019', 'ph_bio_dvst_2015',\n       'ph_max_tem_2019', 'in_night_light_2016'],\n      dtype='object')"
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "#imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# The SimpleImputer\n",
    "si = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "data_x_tran = si.fit_transform(X)\n",
    "\n",
    "\n",
    "# # Standardize  data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "data_x_scale = ss.fit_transform(data_x_tran)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameter\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "data": {
      "text/plain": "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7f1f3fea5454b9aa5356e26f8dbd700"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8703794\ttest: 0.8888889\tbest: 0.8888889 (0)\ttotal: 2.66ms\tremaining: 10.6s\n",
      "500:\tlearn: 0.9388837\ttest: 0.9195402\tbest: 0.9195402 (245)\ttotal: 1.15s\tremaining: 8.06s\n",
      "1000:\tlearn: 0.9589415\ttest: 0.9356725\tbest: 0.9356725 (774)\ttotal: 2.13s\tremaining: 6.39s\n",
      "1500:\tlearn: 0.9717205\ttest: 0.9356725\tbest: 0.9356725 (774)\ttotal: 3.12s\tremaining: 5.19s\n",
      "2000:\tlearn: 0.9790028\ttest: 0.9356725\tbest: 0.9356725 (774)\ttotal: 4.11s\tremaining: 4.1s\n",
      "2500:\tlearn: 0.9838675\ttest: 0.9356725\tbest: 0.9356725 (774)\ttotal: 5.08s\tremaining: 3.05s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 0.9356725146\n",
      "bestIteration = 774\n",
      "\n",
      "Shrink model to first 775 iterations.\n"
     ]
    }
   ],
   "source": [
    "import catboost\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "params = {'loss_function':'Logloss',\n",
    "          'eval_metric':'F1',\n",
    "          'early_stopping_rounds': 2000,\n",
    "          'iterations': 4000,\n",
    "          'verbose': 500,\n",
    "          'random_seed': random_seed,\n",
    "          'l2_leaf_reg': 9,\n",
    "          'bootstrap_type': 'Bayesian',\n",
    "          # 'learning_rate': 0.1,\n",
    "          'bagging_temperature': 2.5\n",
    "         }\n",
    "\n",
    "model = CatBoostClassifier(**params, class_weights=[0.2, 0.8])\n",
    "# model = CatBoostClassifier(**params, scale_pos_weight=1)\n",
    "\n",
    "model.fit(X_train, y_train, # data to train on (required parameters, unless we provide X as a pool object, will be shown below)\n",
    "          eval_set=(X_val, y_val), # data to validate on\n",
    "          use_best_model=True, # True if we don't want to save trees created after iteration with the best validation score\n",
    "          plot=True, # True for visualization of the training process (it is not shown in a published kernel - try executing this code)\n",
    "\n",
    "         );"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: [0.7054747054747055]\n",
      "Recall: [0.7765064836003052]\n",
      "Precision: [0.6463492063492063]\n"
     ]
    }
   ],
   "source": [
    "from catboost.utils import eval_metric\n",
    "# import CatBoost\n",
    "\n",
    "predictions = model.predict(data_x_scale)\n",
    "\n",
    "F1 = eval_metric(y, predictions, 'F1')\n",
    "Precision = eval_metric(y, predictions, 'Precision')\n",
    "Recall = eval_metric(y, predictions, 'Recall')\n",
    "print(\"F1:\", F1)\n",
    "print(\"Recall:\", Recall)\n",
    "print(\"Precision:\", Precision)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "pool_data = Pool(data= data_x_scale,\n",
    "                  label=y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "feature_names = ['po_wp_2020', 'po_hrsl_2018', 'uu_bld_den_2020', 'uu_bld_count_2020',\n",
    "            'ph_slope_2000', 'ph_pm25_2016', 'ph_ndvi_2019', 'ph_bio_dvst_2015',\n",
    "            'ph_max_tem_2019', 'in_night_light_2016']\n",
    "\n",
    "data = pd.DataFrame({'feature_importance': model.get_feature_importance(pool_data),\n",
    "              'feature_names': feature_names}).sort_values(by=['feature_importance'],\n",
    "                                                       ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "data": {
      "text/plain": "   feature_importance        feature_names\n3           88.861660    uu_bld_count_2020\n1            7.081044         po_hrsl_2018\n5            4.044546         ph_pm25_2016\n0            0.012750           po_wp_2020\n2            0.000000      uu_bld_den_2020\n4            0.000000        ph_slope_2000\n6            0.000000         ph_ndvi_2019\n7            0.000000     ph_bio_dvst_2015\n8            0.000000      ph_max_tem_2019\n9            0.000000  in_night_light_2016",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_importance</th>\n      <th>feature_names</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>88.861660</td>\n      <td>uu_bld_count_2020</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.081044</td>\n      <td>po_hrsl_2018</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4.044546</td>\n      <td>ph_pm25_2016</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.012750</td>\n      <td>po_wp_2020</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>uu_bld_den_2020</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>ph_slope_2000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.000000</td>\n      <td>ph_ndvi_2019</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.000000</td>\n      <td>ph_bio_dvst_2015</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.000000</td>\n      <td>ph_max_tem_2019</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.000000</td>\n      <td>in_night_light_2016</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.13160\tvalidation_1-error:0.11765\n",
      "[1]\tvalidation_0-error:0.12906\tvalidation_1-error:0.11765\n",
      "[2]\tvalidation_0-error:0.11964\tvalidation_1-error:0.13235\n",
      "[3]\tvalidation_0-error:0.11904\tvalidation_1-error:0.11765\n",
      "[4]\tvalidation_0-error:0.11889\tvalidation_1-error:0.11765\n",
      "[5]\tvalidation_0-error:0.11709\tvalidation_1-error:0.11765\n",
      "[6]\tvalidation_0-error:0.11231\tvalidation_1-error:0.11765\n",
      "[7]\tvalidation_0-error:0.11111\tvalidation_1-error:0.13235\n",
      "[8]\tvalidation_0-error:0.10737\tvalidation_1-error:0.14706\n",
      "[9]\tvalidation_0-error:0.10378\tvalidation_1-error:0.14706\n",
      "[10]\tvalidation_0-error:0.10049\tvalidation_1-error:0.14706\n",
      "[11]\tvalidation_0-error:0.10049\tvalidation_1-error:0.14706\n",
      "[12]\tvalidation_0-error:0.09930\tvalidation_1-error:0.14706\n",
      "[13]\tvalidation_0-error:0.09571\tvalidation_1-error:0.14706\n",
      "[14]\tvalidation_0-error:0.09526\tvalidation_1-error:0.14706\n",
      "[15]\tvalidation_0-error:0.09391\tvalidation_1-error:0.14706\n",
      "[16]\tvalidation_0-error:0.09047\tvalidation_1-error:0.13235\n",
      "[17]\tvalidation_0-error:0.09017\tvalidation_1-error:0.13235\n",
      "[18]\tvalidation_0-error:0.08539\tvalidation_1-error:0.14706\n",
      "[19]\tvalidation_0-error:0.08644\tvalidation_1-error:0.14706\n",
      "[20]\tvalidation_0-error:0.08330\tvalidation_1-error:0.13235\n",
      "[21]\tvalidation_0-error:0.07986\tvalidation_1-error:0.13235\n",
      "[22]\tvalidation_0-error:0.07896\tvalidation_1-error:0.13235\n",
      "[23]\tvalidation_0-error:0.07851\tvalidation_1-error:0.13235\n",
      "[24]\tvalidation_0-error:0.07806\tvalidation_1-error:0.13235\n",
      "[25]\tvalidation_0-error:0.07597\tvalidation_1-error:0.13235\n",
      "[26]\tvalidation_0-error:0.07492\tvalidation_1-error:0.13235\n",
      "[27]\tvalidation_0-error:0.07328\tvalidation_1-error:0.10294\n",
      "[28]\tvalidation_0-error:0.07178\tvalidation_1-error:0.10294\n",
      "[29]\tvalidation_0-error:0.06819\tvalidation_1-error:0.10294\n",
      "[30]\tvalidation_0-error:0.06700\tvalidation_1-error:0.11765\n",
      "[31]\tvalidation_0-error:0.06729\tvalidation_1-error:0.13235\n",
      "[32]\tvalidation_0-error:0.06535\tvalidation_1-error:0.13235\n",
      "[33]\tvalidation_0-error:0.06490\tvalidation_1-error:0.13235\n",
      "[34]\tvalidation_0-error:0.06281\tvalidation_1-error:0.13235\n",
      "[35]\tvalidation_0-error:0.06191\tvalidation_1-error:0.11765\n",
      "[36]\tvalidation_0-error:0.06191\tvalidation_1-error:0.13235\n",
      "[37]\tvalidation_0-error:0.06206\tvalidation_1-error:0.13235\n",
      "[38]\tvalidation_0-error:0.05922\tvalidation_1-error:0.13235\n",
      "[39]\tvalidation_0-error:0.05728\tvalidation_1-error:0.13235\n",
      "[40]\tvalidation_0-error:0.05757\tvalidation_1-error:0.11765\n",
      "[41]\tvalidation_0-error:0.05728\tvalidation_1-error:0.11765\n",
      "[42]\tvalidation_0-error:0.05742\tvalidation_1-error:0.11765\n",
      "[43]\tvalidation_0-error:0.05563\tvalidation_1-error:0.11765\n",
      "[44]\tvalidation_0-error:0.05503\tvalidation_1-error:0.11765\n",
      "[45]\tvalidation_0-error:0.05324\tvalidation_1-error:0.10294\n",
      "[46]\tvalidation_0-error:0.05339\tvalidation_1-error:0.11765\n",
      "[47]\tvalidation_0-error:0.05354\tvalidation_1-error:0.11765\n",
      "[48]\tvalidation_0-error:0.05309\tvalidation_1-error:0.11765\n",
      "[49]\tvalidation_0-error:0.05219\tvalidation_1-error:0.11765\n",
      "[50]\tvalidation_0-error:0.05144\tvalidation_1-error:0.11765\n",
      "[51]\tvalidation_0-error:0.05114\tvalidation_1-error:0.11765\n",
      "[52]\tvalidation_0-error:0.04995\tvalidation_1-error:0.11765\n",
      "[53]\tvalidation_0-error:0.04800\tvalidation_1-error:0.13235\n",
      "[54]\tvalidation_0-error:0.04711\tvalidation_1-error:0.11765\n",
      "[55]\tvalidation_0-error:0.04726\tvalidation_1-error:0.11765\n",
      "[56]\tvalidation_0-error:0.04711\tvalidation_1-error:0.11765\n",
      "[57]\tvalidation_0-error:0.04711\tvalidation_1-error:0.11765\n",
      "[58]\tvalidation_0-error:0.04696\tvalidation_1-error:0.11765\n",
      "[59]\tvalidation_0-error:0.04441\tvalidation_1-error:0.11765\n",
      "[60]\tvalidation_0-error:0.04277\tvalidation_1-error:0.11765\n",
      "[61]\tvalidation_0-error:0.04337\tvalidation_1-error:0.11765\n",
      "[62]\tvalidation_0-error:0.04202\tvalidation_1-error:0.11765\n",
      "[63]\tvalidation_0-error:0.04083\tvalidation_1-error:0.10294\n",
      "[64]\tvalidation_0-error:0.04068\tvalidation_1-error:0.10294\n",
      "[65]\tvalidation_0-error:0.04038\tvalidation_1-error:0.10294\n",
      "[66]\tvalidation_0-error:0.03933\tvalidation_1-error:0.11765\n",
      "[67]\tvalidation_0-error:0.03933\tvalidation_1-error:0.11765\n",
      "[68]\tvalidation_0-error:0.03813\tvalidation_1-error:0.11765\n",
      "[69]\tvalidation_0-error:0.03739\tvalidation_1-error:0.10294\n",
      "[70]\tvalidation_0-error:0.03873\tvalidation_1-error:0.10294\n",
      "[71]\tvalidation_0-error:0.03739\tvalidation_1-error:0.11765\n",
      "[72]\tvalidation_0-error:0.03619\tvalidation_1-error:0.10294\n",
      "[73]\tvalidation_0-error:0.03619\tvalidation_1-error:0.08824\n",
      "[74]\tvalidation_0-error:0.03559\tvalidation_1-error:0.11765\n",
      "[75]\tvalidation_0-error:0.03380\tvalidation_1-error:0.10294\n",
      "[76]\tvalidation_0-error:0.03425\tvalidation_1-error:0.10294\n",
      "[77]\tvalidation_0-error:0.03245\tvalidation_1-error:0.10294\n",
      "[78]\tvalidation_0-error:0.03230\tvalidation_1-error:0.10294\n",
      "[79]\tvalidation_0-error:0.03245\tvalidation_1-error:0.08824\n",
      "[80]\tvalidation_0-error:0.03125\tvalidation_1-error:0.08824\n",
      "[81]\tvalidation_0-error:0.03111\tvalidation_1-error:0.08824\n",
      "[82]\tvalidation_0-error:0.03036\tvalidation_1-error:0.08824\n",
      "[83]\tvalidation_0-error:0.03111\tvalidation_1-error:0.10294\n",
      "[84]\tvalidation_0-error:0.03140\tvalidation_1-error:0.10294\n",
      "[85]\tvalidation_0-error:0.03036\tvalidation_1-error:0.10294\n",
      "[86]\tvalidation_0-error:0.03096\tvalidation_1-error:0.10294\n",
      "[87]\tvalidation_0-error:0.03066\tvalidation_1-error:0.10294\n",
      "[88]\tvalidation_0-error:0.02946\tvalidation_1-error:0.10294\n",
      "[89]\tvalidation_0-error:0.02961\tvalidation_1-error:0.10294\n",
      "[90]\tvalidation_0-error:0.02931\tvalidation_1-error:0.10294\n",
      "[91]\tvalidation_0-error:0.02856\tvalidation_1-error:0.10294\n",
      "[92]\tvalidation_0-error:0.02826\tvalidation_1-error:0.10294\n",
      "[93]\tvalidation_0-error:0.02841\tvalidation_1-error:0.10294\n",
      "[94]\tvalidation_0-error:0.02722\tvalidation_1-error:0.10294\n",
      "[95]\tvalidation_0-error:0.02632\tvalidation_1-error:0.10294\n",
      "[96]\tvalidation_0-error:0.02587\tvalidation_1-error:0.10294\n",
      "[97]\tvalidation_0-error:0.02557\tvalidation_1-error:0.10294\n",
      "[98]\tvalidation_0-error:0.02453\tvalidation_1-error:0.10294\n",
      "[99]\tvalidation_0-error:0.02453\tvalidation_1-error:0.10294\n"
     ]
    },
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=100, enable_categorical=False,\n              eval_metric='error', feature_types=None, gamma=0, gpu_id=-1,\n              grow_policy='depthwise', importance_type=None,\n              interaction_constraints='', learning_rate=0.300000012,\n              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=7,\n              missing=nan, monotone_constraints='()', n_estimators=100,\n              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=42, ...)",
      "text/html": "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=100, enable_categorical=False,\n              eval_metric=&#x27;error&#x27;, feature_types=None, gamma=0, gpu_id=-1,\n              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=7,\n              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=100, enable_categorical=False,\n              eval_metric=&#x27;error&#x27;, feature_types=None, gamma=0, gpu_id=-1,\n              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=7,\n              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "          'scale_pos_weight': 2.5,\n",
    "          # 'random_seed': random_seed,\n",
    "          #   'binary': 'logisic',\n",
    "          'early_stopping_rounds': 100,\n",
    "          'eval_metric':'error',\n",
    "          'min_child_weight':7,\n",
    "          'subsample': 0.8,\n",
    "          'max_depth' : 5\n",
    "         }\n",
    "\n",
    "# print(grid_search.best_params_)\n",
    "model = XGBClassifier(**params, validate_parameters=True, random_state=random_seed)\n",
    "model.fit(X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: [0.4966849782155711]\n",
      "Recall: [1.0]\n",
      "Precision: [0.3303931451612903]\n"
     ]
    }
   ],
   "source": [
    "from catboost.utils import eval_metric\n",
    "# import CatBoost\n",
    "\n",
    "predictions = model.predict(data_x_scale)\n",
    "\n",
    "F1 = eval_metric(y, predictions, 'F1')\n",
    "Precision = eval_metric(y, predictions, 'Precision')\n",
    "Recall = eval_metric(y, predictions, 'Recall')\n",
    "print(\"F1:\", F1)\n",
    "print(\"Recall:\", Recall)\n",
    "print(\"Precision:\", Precision)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [143], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m data \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeature_importance\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_importances_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpool_data\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m      2\u001B[0m               \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeature_names\u001B[39m\u001B[38;5;124m'\u001B[39m: feature_names})\u001B[38;5;241m.\u001B[39msort_values(by\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeature_importance\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m      3\u001B[0m                                                        ascending\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mTypeError\u001B[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame({'feature_importance': model.feature_importances_(pool_data),\n",
    "              'feature_names': feature_names}).sort_values(by=['feature_importance'],\n",
    "                                                       ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [150], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mseaborn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msns\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "# !pip install seaborn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (2355356520.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn [151], line 12\u001B[0;36m\u001B[0m\n\u001B[0;31m    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True))\u001B[0m\n\u001B[0m                                                                              ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "def plot_feature_importance(importance,names,model_type):\n",
    "\n",
    "    #Create arrays from feature importance and feature names\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    #Create a DataFrame using a Dictionary\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    #Sort the DataFrame in order decreasing feature importance\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True))\n",
    "\n",
    "    #Define size of bar plot\n",
    "    plt.figure(figsize=(10,8))\n",
    "    #Plot Searborn bar chart\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "    #Add chart labels\n",
    "    plt.title(model_type + 'FEATURE IMPORTANCE')\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
